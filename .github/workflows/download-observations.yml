name: Download observations and upload to DynamoDB

on:
  schedule:
    - cron: '0 6 * * *'  # 06:00 UTC
  workflow_dispatch:
    inputs:
      days_back:
        description: "J-X (0 par dÃ©faut). Ex: 1 pour J-1"
        required: false
        default: "1"

permissions:
  id-token: write
  contents: write

concurrency:
  group: download-observations
  cancel-in-progress: false

env:
  MF_BASIC_AUTH_B64: ${{ secrets.MF_BASIC_AUTH_B64 }}
  METEO_TOKEN_CACHE: ${{ github.workspace }}/.cache/mf_token.json
  METEO_MAX_RPM: '50'
  PYTHONUNBUFFERED: '1'

jobs:
  fetch-observations:
    runs-on: ubuntu-latest
    outputs:
      ymd: ${{ steps.date.outputs.YMD }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python + AWS
        uses: ./.github/actions/setup-uv-aws
        with:
          python-version: '3.11'
          role-arn: ${{ secrets.AWS_ROLE_ARN }}
          region: ${{ secrets.AWS_REGION }}
          extra-packages: 'requests python-dateutil boto3'

      - name: Compute target date
        id: date
        shell: bash
        run: |
          DBACK="${{ github.event.inputs.days_back }}"
          [ -z "$DBACK" ] && DBACK="1"
          echo "YMD=$(date -u -d "$DBACK days ago" +%F)" >> "$GITHUB_OUTPUT"

      - name: Cleanup missing registry (keep 11 days)
        shell: bash
        run: python -m src.maintenance.cleanup_missing_observations --days 11

      - name: Fetch missing observations to DDB
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p logs/observations_missing
          (
            python -m src.download.fetch_missing_observations \
              --missing data/metadonnees/missing_observations.json \
              --stations data/metadonnees/stations.json \
              --max-dates-per-id 1 \
              --logdir logs/observations_missing \
              --soft-exit
          ) | tee "logs/observations_missing/jx-${{ steps.date.outputs.YMD }}.csv" \
            | tee /dev/stderr \
            | python -u -m src.upload.stdin_to_dynamodb \
                --table Observations --pk id --sk date --allow-empty

      - name: Fetch J-X to DDB (TTL 11j)
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p logs/observations
          python -m src.download.fetch_observations \
            --date "${{ steps.date.outputs.YMD }}" \
            --stations data/metadonnees/stations.json \
            --logdir logs/observations \
          | tee "logs/observations/jx-${{ steps.date.outputs.YMD }}.csv" \
          | tee /dev/stderr \
          | python -u -m src.upload.stdin_to_dynamodb \
              --table Observations --pk id --sk date --ttl-days 11

      - name: Commit missing_observations.json if changed
        if: ${{ github.ref == 'refs/heads/main' }}
        shell: bash
        run: |
          set -eux
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -N -f data/metadonnees/missing_observations.json || true
          git diff --quiet -- data/metadonnees/missing_observations.json && exit 0
          git add -f data/metadonnees/missing_observations.json
          git commit -m "chore(obs): refresh missing_observations.json [skip ci]"
          git push

      - name: Upload logs + CSV
        uses: actions/upload-artifact@v4
        with:
          name: observations-${{ steps.date.outputs.YMD }}-${{ github.run_id }}
          path: |
            logs/observations/*.log
            logs/observations/*.csv
            logs/observations_missing/*.log
            logs/observations_missing/*.csv
          if-no-files-found: warn
          retention-days: 10

  invoke-export:
    needs: fetch-observations
    uses: NCSdecoopman/SnowViz/.github/workflows/invoke-ddb-export.yml@main
    with:
      function_name: ddb-export-observations-to-github
    secrets:
      AWS_ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
